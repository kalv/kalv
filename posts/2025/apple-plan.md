---
title: Apple Company Plan
description: Review of Apple and it's technology
date: 2025-04-16
layout: layouts/post.njk
tags: ["computers"]
---

My review of Apple as of April 2025 and it's amazing potential for the future.

If I was to be CEO, my theme would be finding fun to florish in all their products, software and hardware.

I would love to walk the floor and just jump into any of the departments to investigate their great work and level it up with years of computer science knowledge. So i went ahead and explored this concept by reviewing a number of their products over the last 3 years.

If I were to be in their offices, I would speak to literally everyone just like Steve Jobs/Wozniak did but not get frustrated with slow progress and work to enable those that struggle to understand the momentum that others take to go, taking learnings I've had with working with Tobias Lutke the CEO of Shopify.

I first wrote a draft of these concepts in Puerto Escodido in Nov 2023 whilst training my body and mind with star theory. I believe what I wrote is still the future and I’d like to start contributing to this work as soon as I can.

# Private AI search index
Creating a local neural network to index a private AI engine to answer questions on content that is indexed from the web or data sources freely available. Such that every family has their own private AI engine. Think of it as a ChatGPT for every household concepts like:
- Family recipes
- History of their family
- Specific news and encyclopedia of data sets freely available from Apple servers.

This indexes can then be shared with the iCloud family sharing feature allowing all parties of a family to leverage and grow the index.

Building on early Search Index retrieval methods rather than full neural networks, and only leveraging neural networks for NLP and better understanding a question to extrapolate a search query or even pre-indexing of content in complex semantic structures that are able to contextually link topics together.

# Developers
Look to investing and growing the ability to run all types of computers on a mac. With a company like [UTM](https://mac.getutm.app/), even promoting the fun emulators for the older machines to run on ARM.

Allowing all forms of open software development on Macs as Steve Wozniak wanted to in his early days of Apple.

Further opening up the extendability of the operating system, originally AppleScript allowed this, to hook up different actions in different applications. Most if not all Apple applications still allow this with the Siri Shortcut feature but it's hidden and complicated to build upon today.

A complete overhal of the developer documentation, it's very difficult to view the API documentation or even understand the different available SDKs/methods/classes on different iOS releases. Needs a sharper approach on versioning new iOS releases, perhaps even locking down core libraries and not change them as much. Example code applications are great within the documentation but difficult to obtain after a WWDC has passed.

# Privacy
Building on great initiatives like the team in Maui [Objective-See](https://objective-see.org/products/oversight.html)

Funding them to stay independent and ensuring that privacy and cybersecurity is top notch for Mac OS. Ensuring that individuals using the machines are safe and feel like they could take on the world when using one.

I made a product called Holopod that allowed the camera to detect when an individual was sitting at their machine such that when they made coffee, it would set a Slack status to say 'making coffee'. This application also monitored the microphone to state when an individual was on a call. Funnily, it found out that Zoom still kept the microphone open after a call. Was a huge security hole. Objective-See team could create a new app in this area. Mac does have a feature today to show a dot in the top right corner to show when the mic is on, but it's not transparent enough to see which application is using what.

Similar to how Linux app stores work, the App Store could have better sections for ‘Security’ to recommend utils. Not all applications should be built into the default Mac, not everyone is security concious and for most home users, lots of notifications would scare them for adoption of the experience.

Signing of applications is top notch but I would really love to see it accessible by all developers. Similar to GNU pgp and not have them all pay for a developer license.

# Touch ID / Security
Grow the adoption of [Passkeys](https://developer.apple.com/passkeys/) with all online services.

Is it possible to get a new Mac and touch it with your fingerprint and it pull down all that is you, as an identity and passwords.

Passkeys are great in accessing websites, making it crystal clear that when you create one for a website like Github that it works.
The 2 factor multi device code would need to be dropped in time, such that an old device you have signed in wouldn’t get the key to allow a 3rd party access to steal the keys

Extending on the use of the Secure Enclave for personal security encryption keys and even [private notes](https://kalv.co.uk/posts/2025/mac-private-notes/)

# Apple Pay
I have nothing to add to this amazing service. Nothing, it’s amazing!! Brilliant work by the team, being able to pay for goods at Budgens or your local superstore.

The concept of this becoming your bank is huge and removes the nonense of crypto currencies, as the world works with the countries currency they have at hand.

# Unify app development
A little bit of a rant. Is it Objective-C or SwiftUI.

I find that the application core launch approaches aren't that compatible between the two, and having to always write workarounds or the documentation isn't clear how they both work well with one another.

It needs better ability to use Objective C and SwiftUI together. Such that a SwiftUI class structure of an application works on top of Objective-C. Not one or the other. Having an application developer pick between the two is a struggle. We need to have developers be able to introduce the magic of SwiftUI into an existing Objective-C app. Similar to how Java Swing would allow UI be created on powerful programming models in Java.

# Apple Watch
Work to make it lower power, with similiar iOS optimizations I list out further in this document. The fact that the watch doesn’t last a week is broken

How is the display being rendered, why is it that it sucks so much power, can a new x window manager be created or collaborations be made with those that are working at [Pine](https://pine64.org/devices/pinetime/) or other platforms to run a lower energy version of the viewing of applications. I miss the [Pebble Watch](https://en.wikipedia.org/wiki/Pebble_(watch)) for this purpose, their apps worked, I was able to build custom applications and the screen/power usage worked for a full week.

Other quesitons and areas I would research, can developers profile their power usage, what is running in the background.

Introduce a personal clock for individuals that want to work with different times.
https://kalv.co.uk/clock/ - My Mind clock, think of it as a way to not be stressed with the time and deadlines. Letting your mind focus or be used for Transcendental Meditation, allowing you to not to care for on your breathing for 1,2,3 minutes, with your chai.

Introduce more music apps for musicians, such as one I call Tap. To tap it and make a metronome, would be a great utility to add in the next watch OS.

Use different fonts, like the font from the beginning of TRON, making it fun to see.

Listening to music using the microphone and then determining the BPM such that DJs could use it.

Could be a great demo for the Apple Watch and DJs for the next WWDC.

# Operating System
Tuning the operating system kernel with Ashai Linux team. Purchasing and growing them, to keep the ashai linux in place but then allowing Fedora core team to contribute other the core Mac OS kernel allowing for cross development with the mini creative devices.

A full UI overhaul, specifically Settings, it's messy, un-structured and difficult to find settings. There are many places to set the voice for speech for example. It's as though the core settings to be shared across all applications have been moved into app specific settings and that's cause fragmentation of setting a choice once and not having it propagate across all applications.

# Creatives
Lifting up the use of Lidar, taking my concept of [Nort](/posts/2025/nort/) further.

Creating a social network for creatives to capture the world they love and sharing with those around them. Better than YouTube. Using the feature of Lidar and the ability to publish to the web.

Children and creatives around the world, can capture Joy of the world they see and share it

VisionOS can then allow those around the world that are impaired and can’t access it easily.

 E.g Being able to record a unique hike in Revelstoke heading down to a unique thermal waters and others in the world being able to view it.

I had originally that 3d YouTube would do this in that those around the world would be able to capture their experiences and allow VR goggles would allow it to be displayed.
But the challenge is capturing high quality video at high resolutions and being able to upload and process it.  “Mini Creative stations” would allow this with KonDB. A new form of multimedia compression and sharing.
# Future of Web

Acceesible content for all, why is it not possible for everyone to have a blog, discover them. Why is it we have so many social media platforms. Where did MobileMe (for those that remember it) go?

It would be great to have all content being created on Apple a unique URI such that anyone is able to view it publicly when the user decides.

Even if it were to start as a photo/video gallery again on a unique URL, it would be great to allow others to see the creations one would make from an Apple product.

# Mobile
Turning off iMessage and moving to a full spec of RCS. And contributing any of the learnings to the open spec, such that it’s cross compatible with Android. Allowing all to message all.

The work that Apple has been doing allows for offline speech synthesis has been wonderful, I was able to train my voice the other day even though I can't get it fully configured to speak my text on the mac using it yet. It shows that a lot is possible offline. I now ponder what is possible if there is an offline Language translation system on device. The translation of English to another language. It seems that this looks possible using their [Translation](https://developer.apple.com/documentation/translation) developer APIs. This would open up the world such that you could text between an english speaker and a spanish speaker seemlessly. Not having the need to translate it, you could set the language of a contact.

Kernel optimizations for iOS could be made on all iOS devices, to allow them to double if not triple their battery life and performance using better optimized CPU frequency processing. Having the device sit idle should sip battery. Rendering could be adpated to ensure using the GPU and only having rendering occur with different timing clock, so that the loop of graphics rendering is performant. Even the linux kernel timing could be optimized to not just work as a loop, something that has not been investigated in unix kernel development since the conception.

A new retro Camera app, I call Snap. Bringing a fun app that allows photographers th open the app quickly and allowing them to easily switch the settings similiar to how a manual camera works, like my old Minolta 7s.
The screen settings could have switches and defaults like 1/250, F8, ISO to capture fun exposures without the 'auto' setting. Allowing children to learn the basics of photography and create unique constrast photos.

This would allow creatives to capture the way photographers would in the past, limiting them and by removing the ‘auto’ aspect it makes the human mind learn about the joy of thinking about a frame capture. Could literally be a mode in the camera app. Or move the functionality out into 2 apps depending on how the Apple development prototypes the experience.

# Voice Control
Voice control, the possibilities here are huge. There are voice control actions but nothing that is bundled together, such that say 'build' is a command that an Xcode developer could say to speed up their workflow.

# Faster sharing / Music/Video Publishing
Building on P2P as the cloud mechanism for sharing of multimedia, peer to peer.
https://kalv.co.uk/just-share/
Similiar to the introduction of MMS, iMessage were the first to allow higher resolution photos be transferred across their Apple network, this could be an extension on RCS or another protocol to allow fast transfer of locally encoded video/photos that are optimized for low bandwidth size.

Being able to create locally encoded and ready content, the chips on mobile and desktop using ARM are great. They have Apple Accelerate ready to go.

A live network isn't something I'd encourage in an ecosystem as creatives very rarely would like to have comments on their work when creating it. I would see it as:
- Being able to record high quality audio and stream it, even if in spatial audio, using the full 3 or 4 microphones available on iPhones and iPads to capture creatives environments to be listened to those that have spatial headphones.
- Using Apple Accelerate to encode as a stream and upload it as it's required.
- Focussing on publishing it fast and small, as great musicians would want to share great music studio sessions and not care too much about the visuals

The Visuals can be generated or other effects using lidar / augmented objects in display can be added to make it fun.

Not thinking about how it will be viewed by many people at the same time, as the file will exist after it's published. Not so much making this a live view and comment, as musicians will never want to have comments and discuss their music as they are publishing it.

# A faster lighter weight network
Being able to use old TV aerials and creating a dongle that will allow anyone to connect their phone to a Co-axial or aerial connection to use a new type of modem to take advantage of multi band FM signals for faster data transfers and longer distances without having to putting sattelites in the sky. Clouding the beautiful stars at night.

It would be great for Apple to release this in Africa and Mexico.

# Apple Music
Allowing creatives to create easy push to publish music for all the music creators of the world.
Not having to worry about the video or recording themselves make their music. Think of AVCII being able to push a button and having his studio mixes just be freely available. A better Soundcloud that is free.
A great path for music artists to practice, have listeners and then grow to having them become larger artists on Apple Music or even radio stations for their friends.
Why is it not possible for small bedroom DJs to have 100s of listeners of their friends, great social aspects and allow them to share music curation and bubble up great artists that are small and medium across the world.

Car karaoke with their friends, being able to push a button and have someone sing along to their curation of tracks, would need to adapt CarPlay to have microphone input as well as playback
(Larger dev effort to make a better sound engine, could use the development effort already in progress with the ashai linux, such that ashai linux gains and so does Mac OS for a better pipelining

Music on the Mac, needs more visualizations for fun experiences of an individual playing the latest Strombo Podcast and having the display show great visualizations, perhaps things that Strombo would influence in his experiences of music and Toronto.

Work with the old Last.fm team to build out a better https://www.shazam.com/en-gb/shazamkit and sharing of the music listens for those that listen to Apple Music.
Being able to hum

Listening [experiences for the deaf](/posts/2025/deaf-music-experience/), A visual, hardware vibration experience to play any song with lyrics, visualizations and the ability to make them to dance to a song in silence, allowing them to dance like no one is watching and not care, to feel the joy of their own body and FUN.

# USB-C sound
To further grow Spatial Audio.
Built out a new new audio pipeline to be created with USB-C sound outputs, rather than 3.5mm audio jacks, allowing for a possibility of having less cabling, the USB-C data interface would allow for high quality and low latency raw PCM data.

# Staff / People
Ensuring it remains diverse, global and async if required but always with physical connectivity.
New forms of psychology to allow those that are on the spectrum to work anytime they want, day or night to create the best possible creations. I'll have to blog further about this as my research is not ready but it considers that your life doesn't consist of just Zeros and Ones, choices aren't just one way or the other. Contextual thinking and considering multiple variables to your decision and mental thinking. My mind clock builds on this in that no one needs to consider just the hour and the minute, you can have whatever clock works for you, mine is what I call a 1,5,60, essentially creating 3 ticks of unique time reference for your mind. You can take a look at this in my Visualization tool on this website.

The company does not build just software, products, or hardware, but creations.

# A mini creative device
Using the old iPhone 7s and other devices to run a lighter weight operating system tuned for offline/online and media work only.
- Quick snaps of creative captures
- Easy / encoding and uploading using on device acceleration, Apple Accelerate (Handbrake optimizations led to 1000fps on a MacBook Air m2)
- iPads could load this firmware/OS that will allow them to use the faster processing and higher hardware specifications
- Great example of this today in 2025 is the HDMI screens that get added on to DSLRs, but these will have compute available
- Voice controlled actions/commands for easy use in the field and allow the creatives to capture details on what they do, such as even capturing details like shutter / aperture details of a photo
- Audio or text journalling

# Apple Journalling and notes
Apple Voice Memos / Notes / Journal should merge together. I'm unsure why they've forked out to different products.
Allowing transcription and search to work across all forms of note capturing

Creatives and explorers would be able to capture faster with voice and headphones and then be able to cross reference their knowledge.

This knowledge can then be placed in the private AI for their families and models that are shared with staff.
Think of a team working on something revolutionary and being able to capture all together rather than post in to a Slack channel of noise. Research, Research, Research and then be able to refine as they GO.

The teams are all working on the right problems but unified to ensure that there are less applications on the Apple eco-system

Accessibility team that is working on concepts like personal speech synthesis to then be able to play the notes to other people in asynchronous catch ups with a personal voice.

Structure on notes can be built automatically such that the ‘add note’ works with a box and the note is linked automatically to relevant sections with perhaps even the hash. So that you can easily pull all thoughts related to one topic. Using Semantic structures.

This all would improve how Spotlight works for your creative content.
